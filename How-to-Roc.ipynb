{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial shows how to compute sensitivity, specificity and\n",
    "predictive values in R. It also shows how to obtain ROC curves based\n",
    "on logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Pima diabetes data set https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "library(MASS)\n",
    "library(pROC)\n",
    "\n",
    "# Load the Pima Indians Diabetes dataset\n",
    "data(Pima.tr, package=\"MASS\")\n",
    "data(Pima.te, package=\"MASS\")\n",
    "\n",
    "# Read about the data set\n",
    "?Pima.te\n",
    "\n",
    "# see a sample of the data\n",
    "head(Pima.te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some training data, and some test data.  Here we show how to randomly sample the data, even though with this data set, you could skip this part, because they provde split dataset already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine training and test data for splitting\n",
    "pima_data <- rbind(Pima.tr, Pima.te)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "set.seed(123) # for reproducibility\n",
    "trainingIndex <- sample(1:nrow(pima_data), 0.7*nrow(pima_data))\n",
    "trainData <- pima_data[trainingIndex, ]\n",
    "testData <- pima_data[-trainingIndex, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's train our model.  Here I will use only glucose as the predictor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model using only glucose as the predictor\n",
    "model <- glm(type ~ glu, data = trainData, family = 'binomial')\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make some predictions as to whether the individual has diabetes.  We set a threshold beyond which the likelihood is indicative to us that diabetes is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Making predictions on the test set\n",
    "predictions <- predict(model, newdata = testData, type = \"response\")\n",
    "head(predictions)\n",
    "\n",
    "# Binarize predictions based on a threshold (e.g., 0.5)\n",
    "threshold <- 0.5\n",
    "classPredictions <- ifelse(predictions > threshold, 1, 0)\n",
    "head(classPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll calculate ROC, AUC and show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the ROC curve and AUC\n",
    "roc_curve <- roc(testData$type, as.numeric(predictions))\n",
    "plot(roc_curve, main = \"ROC Curve\")\n",
    "auc_value <- auc(roc_curve)\n",
    "print(paste(\"AUC:\", auc_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll show the confusion matrix which is useful to show PPV and NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# the basic confusion matrix table\n",
    "table(testData$type, classPredictions)\n",
    "#install.packages(\"yardstick\")\n",
    "library(yardstick)\n",
    "library(dplyr)\n",
    "\n",
    "# Convert actual and predicted values to factors\n",
    "actual <- as.numeric(testData$type)\n",
    "actual <- actual - 1\n",
    "actual <- factor(actual, levels = c(0, 1))\n",
    "predicted <- factor(classPredictions)\n",
    "\n",
    "# Create a tibble with the true and predicted values\n",
    "results <- tibble(\n",
    "  truth = actual,\n",
    "  estimate = predicted\n",
    ")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix <- conf_mat(results, truth, estimate)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy_result <- accuracy(results, truth, estimate)\n",
    "print(accuracy_result)\n",
    "\n",
    "# Compute and print sensitivity\n",
    "sensitivity_result <- sens(results, truth, estimate)\n",
    "print(sensitivity_result)\n",
    "\n",
    "# Compute and print specificity\n",
    "specificity_result <- spec(results, truth, estimate)\n",
    "print(specificity_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data, Framingham data set\n",
    "\n",
    "For the purpose of illustration we use the Framingham data. We work\n",
    "with coronary heart disease outcome (detected at any future\n",
    "examination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Framingham <- read.table(\"https://publicifsv.sund.ku.dk/~tag/Teaching/share/data/Framingham.txt\",sep=\" \")\n",
    "Framingham <- read.table(\"https://gist.githubusercontent.com/kkholst/60512439ce0fca7f07a79e2728a6a4d5/raw/95dd3640a55b94c74d03aa1e18bef3d5120d3510/framingham.txt\",sep=\",\", header=TRUE)\n",
    "head(Framingham)\n",
    "Framingham$chd <- factor(Framingham$CHD>0,levels=c(FALSE,TRUE),labels=c(\"event-free\",\"chd\")) \n",
    "head(Framingham)\n",
    "\n",
    "# More complex Framingham set:\n",
    "framinghamLong <- read.csv(\"frmgham2.csv\")\n",
    "head(framinghamLong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## In-Class Exercise: Cardiovascular Disease Prediction Model\n\nBuild a logistic regression model to predict cardiovascular disease using the Framingham Heart Study data.\n\n### Using the Simple Dataset (`Framingham`)\nAvailable predictors: `SBP` (systolic blood pressure), `DBP` (diastolic blood pressure), `CHOL` (cholesterol), `AGE`, `BMI`, `SMOKE`, `DIABETES`\n\n### Your Task:\n\n1. **Data Preparation:**\n   - Explore the Framingham dataset structure\n   - Split into 70% training / 30% test sets using `set.seed(456)` for reproducibility\n\n2. **Model Building:**\n   - Build a logistic regression model predicting `chd` using at least 3 predictors\n   - Examine the model summary - which predictors are significant?\n\n3. **Model Evaluation:**\n   - Generate predicted probabilities on the test set\n   - Create an ROC curve and calculate the AUC\n   - Create a confusion matrix using threshold = 0.5\n\n4. **Analysis Questions:**\n   - What is your model's AUC? Is it better than random guessing (AUC = 0.5)?\n   - Calculate sensitivity and specificity at threshold = 0.5\n   - If you wanted to catch more true cases of CHD (higher sensitivity), how would you adjust the threshold?\n   - What trade-off does this create?\n\n### Bonus Challenge:\nTry the more complex longitudinal dataset (`framinghamLong`) which has additional variables like `PREVCHD`, `PREVAP`, `PREVMI`, `PREVSTRK`. Can you build a better model?"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 1: Data Preparation\nset.seed(456)\ntrain_idx <- sample(1:nrow(Framingham), 0.7 * nrow(Framingham))\ntrain_fram <- Framingham[train_idx, ]\ntest_fram <- Framingham[-train_idx, ]\n\ncat(\"Training size:\", nrow(train_fram), \"\\n\")\ncat(\"Test size:\", nrow(test_fram), \"\\n\")\n\n# Step 2: Build your model\n# Your code here: glm(chd ~ ..., data = train_fram, family = binomial)\n\n\n# Step 3: Model Evaluation\n# Your code here: predictions, ROC curve, confusion matrix\n\n\n# Step 4: Analysis - write your answers as comments\n# "
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
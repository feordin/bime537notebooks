{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1643223254734
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(mtcars)\n",
    "help(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's graph a logistic regression where we try to predict horse power based on a V engine or Straight (inline) engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "#plot logistic regression curve\n",
    "ggplot(mtcars, aes(x=hp, y=vs)) + \n",
    "  geom_point(alpha=.5) +\n",
    "  stat_smooth(method=\"glm\", se=FALSE, method.args = list(family=binomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try to predict automatic or manual based on horsepower and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1643223289056
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model = glm(formula=am ~ hp + wt, data=mtcars, family=binomial)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mpgModel = glm(formula=mpg ~ hp + drat, data=mtcars)\n",
    "summary(mpgModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1643223610185
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "data = ISLR::Default\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1643223661783
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model = glm(default~student+balance+income, family=\"binomial\", data=data)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot_logistic_curve(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## In-Class Exercise: Predicting Species with Logistic Regression\n\nUsing the built-in `iris` dataset, build a logistic regression model to classify iris species.\n\n### Part 1: Binary Classification\nSince logistic regression requires a binary outcome, we'll predict whether a flower is \"virginica\" or not:\n\n1. Create a new binary variable: `is_virginica <- ifelse(iris$Species == \"virginica\", 1, 0)`\n2. Build a logistic regression model using `Sepal.Length` and `Sepal.Width` as predictors\n3. Examine the model summary - which predictor is significant?\n\n### Part 2: Add More Predictors\n1. Build a second model that includes all four measurements (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)\n2. Compare the AIC values of both models - which is better?\n3. Which predictors are significant in the full model?\n\n### Part 3: Interpretation\n1. For the best model, interpret the coefficients - what does a positive coefficient mean?\n2. Use `predict(model, type=\"response\")` to get predicted probabilities\n3. What probability threshold would you use to classify a flower as virginica?\n\n**Hint:** Use `family=binomial` in the `glm()` function for logistic regression",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Part 1: Create binary outcome and simple model\ndata(iris)\niris$is_virginica <- ifelse(iris$Species == \"virginica\", 1, 0)\n\n# Your code here: Build the model\n\n\n# Part 2: Full model with all predictors\n# Your code here\n\n\n# Part 3: Predictions and interpretation\n# Your code here",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "ir"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}